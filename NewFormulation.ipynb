{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Constants =====\n",
    "# LOSS_RATE = 0  # Default\n",
    "LOSS_RATE = -1\n",
    "# LOSS_RATE = -1e-3\n",
    "\n",
    "GAMMA = 0.9999  # Default\n",
    "# GAMMA = 0.99\n",
    "# GAMMA = 1 - 1e-3\n",
    "\n",
    "N_BINS = 1\n",
    "N_GOALS = 10\n",
    "N_TASKS = 50\n",
    "\n",
    "PLANNING_FALLACY_CONST = 1  # Default\n",
    "# PLANNING_FALLACY_CONST = 1.39\n",
    "\n",
    "# SLACK_REWARD = np.NINF\n",
    "# SLACK_REWARD = 1\n",
    "# SLACK_REWARD = 1e-1\n",
    "# SLACK_REWARD = 1e-2\n",
    "SLACK_REWARD = 1e-3\n",
    "\n",
    "TIME_SCALE = 1  # Default\n",
    "# TIME_SCALE = 60\n",
    "\n",
    "VALUE_SCALE = 1  # Default\n",
    "# VALUE_SCALE = 10\n",
    "\n",
    "# UNIT_PENALTY = 10\n",
    "UNIT_PENALTY = 1\n",
    "# UNIT_PENALTY = .1\n",
    "# UNIT_PENALTY = float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from todolistMDP.to_do_list import  *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item: Task A11 Time Estimate: 3\n",
      "Item: Task A12 Time Estimate: 2\n",
      "Item: Task A13 Time Estimate: 2\n",
      "Item: SG A1 Time Estimate: 7\n",
      "Item: Task A21 Time Estimate: 3\n",
      "Item: Task A22 Time Estimate: 1\n",
      "Item: Task A23 Time Estimate: 1\n",
      "Item: SG A2 Time Estimate: 5\n",
      "Item: Goal A Time Estimate: 12\n",
      "Item: Task B11 Time Estimate: 4\n",
      "Item: Task B12 Time Estimate: 2\n",
      "Item: SG B1 Time Estimate: 6\n",
      "Item: Task B21 Time Estimate: 2\n",
      "Item: Task B22 Time Estimate: 2\n",
      "Item: Task B23 Time Estimate: 1\n",
      "Item: Task B24 Time Estimate: 10\n",
      "Item: Task B25 Time Estimate: 2\n",
      "Item: SG B2 Time Estimate: 17\n",
      "Item: Goal B Time Estimate: 23\n",
      "Item: Task C11 Time Estimate: 1\n",
      "Item: Task C12 Time Estimate: 2\n",
      "Item: SG C1 Time Estimate: 3\n",
      "Item: Task C21 Time Estimate: 50\n",
      "Item: Task C22 Time Estimate: 400\n",
      "Item: Task C23 Time Estimate: 50\n",
      "Item: Task C24 Time Estimate: 2\n",
      "Item: SG C2 Time Estimate: 502\n",
      "Item: Goal C Time Estimate: 505\n"
     ]
    }
   ],
   "source": [
    "d_bm_realistic = [\n",
    "    Item(\n",
    "        description=\"Goal A\",\n",
    "        completed=False,\n",
    "        intrinsic_reward=70,\n",
    "        essential=True,\n",
    "        deadline=12,\n",
    "        time_est=TIME_SCALE * 12,\n",
    "        value=1000,\n",
    "        today=True,\n",
    "        children=[\n",
    "            Item(\"SG A1\", time_est=TIME_SCALE * 7, essential=True, importance=30, value=1000, intrinsic_reward=40, today=True,\n",
    "                 completed=False, deadline=12, children=[\n",
    "                Item(\"Task A11\", time_est=TIME_SCALE * 3, essential=True, importance=60, value=1000, intrinsic_reward=10, today=True,\n",
    "                     completed=False, deadline=12),\n",
    "                Item(\"Task A12\", time_est=TIME_SCALE * 2, essential=True, importance=20, value=1000, intrinsic_reward=15, today=True,\n",
    "                     completed=False, deadline=12),\n",
    "                Item(\"Task A13\", time_est=TIME_SCALE * 2, essential=True, importance=20, value=1000, intrinsic_reward=15, today=True,\n",
    "                     completed=False, deadline=12)\n",
    "            ]),\n",
    "            Item(\"SG A2\", time_est=TIME_SCALE * 5, essential=True, importance=30, value=1000, intrinsic_reward=30, today=True,\n",
    "                 completed=False, deadline=12, children=[\n",
    "                Item(\"Task A21\", time_est=TIME_SCALE * 3, essential=True, importance=60, value=1000, intrinsic_reward=20, today=True,\n",
    "                     completed=False, deadline=12),\n",
    "                Item(\"Task A22\", time_est=TIME_SCALE * 1, essential=True, importance=30, value=1000, intrinsic_reward=2, today=True,\n",
    "                     completed=False, deadline=12),\n",
    "                Item(\"Task A23\", time_est=TIME_SCALE * 1, essential=True, importance=10, value=1000, intrinsic_reward=8, today=True,\n",
    "                     completed=False, deadline=12)\n",
    "                 ])\n",
    "        ]),\n",
    "        \n",
    "    Item(\n",
    "        description=\"Goal B\",\n",
    "        completed=False,\n",
    "        intrinsic_reward=200,\n",
    "        essential=True,\n",
    "        deadline=50,\n",
    "        time_est=TIME_SCALE * 23,\n",
    "        value=500,\n",
    "        today=True,\n",
    "        children=[\n",
    "            Item(\"SG B1\", time_est=TIME_SCALE * 6, essential=True, importance=50, value=500, intrinsic_reward=100,\n",
    "                 today=True,\n",
    "                 completed=False, deadline=50, children=[\n",
    "                    Item(\"Task B11\", time_est=TIME_SCALE * 4, essential=True, importance=90, value=500,\n",
    "                         intrinsic_reward=80, today=True,\n",
    "                         completed=False,deadline=50),\n",
    "                    Item(\"Task B12\", time_est=TIME_SCALE * 2, essential=True, importance=10, value=500,\n",
    "                         intrinsic_reward=20, today=True,\n",
    "                         completed=False,deadline=50)\n",
    "                ]),\n",
    "            Item(\"SG B2\", time_est=TIME_SCALE * 17, essential=True, importance=50, value=500, intrinsic_reward=100,\n",
    "                 today=True,\n",
    "                 completed=False, deadline=50, children=[\n",
    "                    Item(\"Task B21\", time_est=TIME_SCALE * 2, essential=True, importance=20, value=500,\n",
    "                         intrinsic_reward=20, today=True,\n",
    "                         completed=False, deadline=50),\n",
    "                    Item(\"Task B22\", time_est=TIME_SCALE * 2, essential=True, importance=60, value=500,\n",
    "                         intrinsic_reward=10, today=True,\n",
    "                         completed=False, deadline=50),\n",
    "                     Item(\"Task B23\", time_est=TIME_SCALE * 1, essential=True, importance=2, value=500,\n",
    "                         intrinsic_reward=10, today=True,\n",
    "                         completed=False, deadline=50),\n",
    "                     Item(\"Task B24\", time_est=TIME_SCALE * 10, essential=True, importance=15, value=500,\n",
    "                         intrinsic_reward=40, today=True,\n",
    "                         completed=False, deadline=50),\n",
    "                     Item(\"Task B25\", time_est=TIME_SCALE * 2, essential=True, importance=3, value=500,\n",
    "                         intrinsic_reward=20, today=True,\n",
    "                         completed=False, deadline=50)\n",
    "                 ])\n",
    "        ]),\n",
    "    Item(\n",
    "        description=\"Goal C\",\n",
    "        completed=False,\n",
    "        intrinsic_reward=100,\n",
    "        essential=True,\n",
    "        deadline=50,\n",
    "        time_est=TIME_SCALE * 505,\n",
    "        value=5000,\n",
    "        today=True,\n",
    "        children=[\n",
    "            Item(\"SG C1\", time_est=TIME_SCALE * 3, essential=True, importance=20, value=5000, intrinsic_reward=10,\n",
    "                 today=True,\n",
    "                 completed=False, deadline=50, children=[\n",
    "                    Item(\"Task C11\", time_est=TIME_SCALE * 1, essential=True, importance=60, value=5000,\n",
    "                         intrinsic_reward=5, today=True,\n",
    "                         completed=False, deadline=50),\n",
    "                    Item(\"Task C12\", time_est=TIME_SCALE * 2, essential=True, importance=40, value=5000,\n",
    "                         intrinsic_reward=5, today=True,\n",
    "                         completed=False, deadline=50)\n",
    "                ]),\n",
    "            Item(\"SG C2\", time_est=TIME_SCALE * 502, essential=True, importance=80, value=5000, intrinsic_reward=90,\n",
    "                 today=True,\n",
    "                 completed=False, deadline=50, children=[\n",
    "                    Item(\"Task C21\", time_est=TIME_SCALE * 50, essential=True, importance=20, value=5000,\n",
    "                         intrinsic_reward=50, today=True,\n",
    "                         completed=False, deadline=50),\n",
    "                    Item(\"Task C22\", time_est=TIME_SCALE * 400, essential=True, importance=60, value=5000,\n",
    "                         intrinsic_reward=10, today=True,\n",
    "                         completed=False, deadline=50),\n",
    "                    Item(\"Task C23\", time_est=TIME_SCALE * 50, essential=True, importance=10, value=5000,\n",
    "                         intrinsic_reward=20, today=True,\n",
    "                         completed=False, deadline=50),\n",
    "                    Item(\"Task C24\", time_est=TIME_SCALE * 2, essential=True, importance=10, value=5000,\n",
    "                         intrinsic_reward=10, today=True,\n",
    "                         completed=False, deadline=50)\n",
    "                 ])\n",
    "        ])\n",
    "\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item: Task A11 Time Estimate: 1\n",
      "Item: Task A12 Time Estimate: 1\n",
      "Item: Task A13 Time Estimate: 1\n",
      "Item: SG A1 Time Estimate: 3\n",
      "Item: Task A21 Time Estimate: 1\n",
      "Item: Task A22 Time Estimate: 1\n",
      "Item: Task A23 Time Estimate: 1\n",
      "Item: SG A2 Time Estimate: 3\n",
      "Item: Goal A Time Estimate: 6\n"
     ]
    }
   ],
   "source": [
    "d_1g_2_sg_imp = [\n",
    "    Item(\n",
    "        description=\"Goal A\",\n",
    "        completed=False,\n",
    "        intrinsic_reward=0,\n",
    "        essential=True,\n",
    "        deadline=TIME_SCALE *12,\n",
    "        time_est=TIME_SCALE * 9,\n",
    "        value=100,\n",
    "        today=True,\n",
    "        children=[\n",
    "            Item(\"SG A1\", time_est=TIME_SCALE * 3, essential=True, importance=90, value=100, intrinsic_reward=0, today=True,\n",
    "                 completed=False, deadline=12, children=[\n",
    "                Item(\"Task A11\", time_est=TIME_SCALE * 1, essential=True, importance=30, value=100, intrinsic_reward=0, today=True,\n",
    "                     completed=False, deadline=12),\n",
    "                Item(\"Task A12\", time_est=TIME_SCALE * 1, essential=True, importance=30, value=100, intrinsic_reward=0, today=True,\n",
    "                     completed=False, deadline=12),\n",
    "                Item(\"Task A13\", time_est=TIME_SCALE * 1, essential=True, importance=30, value=100, intrinsic_reward=0, today=True,\n",
    "                     completed=False, deadline=12)\n",
    "            ]),\n",
    "            Item(\"SG A2\", time_est=TIME_SCALE * 3, essential=True, importance=10, value=100, intrinsic_reward=0, today=True,\n",
    "                 completed=False, deadline=12, children=[\n",
    "                Item(\"Task A21\", time_est=TIME_SCALE * 1, essential=True, importance=3, value=100, intrinsic_reward=0, today=True,\n",
    "                     completed=False, deadline=12),\n",
    "                Item(\"Task A22\", time_est=TIME_SCALE * 1, essential=True, importance=3, value=100, intrinsic_reward=0, today=True,\n",
    "                     completed=False, deadline=12),\n",
    "                Item(\"Task A23\", time_est=TIME_SCALE * 1, essential=True, importance=4, value=100, intrinsic_reward=0, today=True,\n",
    "                     completed=False, deadline=12)\n",
    "                 ])\n",
    "        ])\n",
    "\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item: Root Time Estimate: 6\n"
     ]
    }
   ],
   "source": [
    "main = MainToDoList(d_1g_2_sg_imp, gamma=GAMMA, loss_rate= LOSS_RATE, num_bins=N_BINS, penalty_rate=PLANNING_FALLACY_CONST,slack_reward_rate=SLACK_REWARD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(main.nodes['Goal A'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********** In MainToDoList solve ***********\n",
      "*********** MDP ***********\n",
      "Solving goal as: Root\n",
      "Root Val: 100\n",
      "Solving for following items\n",
      "Goal A, Imp: 1.0, Int: 0, Ess: False\n",
      "Value: 100\n",
      "Called solve_next_item: s: (0,), t: 0\n",
      "State: (0,), s_: (1,)\n",
      "Time_est: 9, Cum_discount: 6.997900349965002, Loss_rate: -1\n",
      "Just Loss Term: -6.997900349965002\n",
      "Adding reward: 100.0, Net: 93.00209965003499\n",
      "Multiplying with prob_t: 1.0: Exp_task_reward: 93.00209965003499\n",
      "Called solve_next_item: s: (1,), t: 9\n",
      "For s_: (1,), t_: 9, Qs: {None: 0}\n",
      "r: 93.00209965003499 + r_: 0 * 0.9994001499800017 \n",
      "Total Reward: 93.00209965003499\n",
      "Exp_total_reward: 93.00209965003499\n",
      "Storing Q-value of Goal A: 93.00209965003499\n",
      "Policy:\n",
      "Action: 0\n",
      "s, t: ((0,), 0), a: 0, s_, t_: ((1,), 0)\n",
      "Slack Action Chosen. Action: None, q: 0 <= 10.000000000001101\n",
      "Q value\n",
      "Goal A, reward: 93.00209965003499 Q: 93.00209965003499\n",
      "[93.00209965003499]\n",
      "Transferrred Q_s0 value down\n",
      "Goal A value dict:93.00209965003499\n",
      "*********** MDP ***********\n",
      "Solving goal as: Goal A\n",
      "Goal A Val: 93.00209965003499\n",
      "Solving for following items\n",
      "SG A1, Imp: 90, Int: 0, Ess: True\n",
      "SG A2, Imp: 10, Int: 0, Ess: True\n",
      "Value: 93.00209965003499\n",
      "Called solve_next_item: s: (0, 0), t: 0\n",
      "State: (0, 0), s_: (1, 0)\n",
      "Time_est: 3, Cum_discount: 2.99970001, Loss_rate: -1\n",
      "Just Loss Term: -2.99970001\n",
      "Adding reward: 0.0, Net: -2.99970001\n",
      "Multiplying with prob_t: 1.0: Exp_task_reward: -2.99970001\n",
      "Called solve_next_item: s: (1, 0), t: 3\n",
      "State: (1, 0), s_: (1, 1)\n",
      "Time_est: 3, Cum_discount: 2.99970001, Loss_rate: -1\n",
      "Just Loss Term: -2.99970001\n",
      "Adding reward: 93.00209965003499, Net: 90.002399640035\n",
      "Multiplying with prob_t: 1.0: Exp_task_reward: 90.002399640035\n",
      "Called solve_next_item: s: (1, 1), t: 6\n",
      "For s_: (1, 1), t_: 6, Qs: {None: 0}\n",
      "r: 90.002399640035 + r_: 0 * 0.9997000299990001 \n",
      "Total Reward: 90.002399640035\n",
      "Exp_total_reward: 90.002399640035\n",
      "For s_: (1, 0), t_: 3, Qs: {1: 90.002399640035}\n",
      "r: -2.99970001 + r_: 90.002399640035 * 0.9997000299990001 \n",
      "Total Reward: 86.97570161012499\n",
      "Exp_total_reward: 86.97570161012499\n",
      "Storing Q-value of SG A1: 86.97570161012499\n",
      "State: (0, 0), s_: (0, 1)\n",
      "Time_est: 3, Cum_discount: 2.99970001, Loss_rate: -1\n",
      "Just Loss Term: -2.99970001\n",
      "Adding reward: 0.0, Net: -2.99970001\n",
      "Multiplying with prob_t: 1.0: Exp_task_reward: -2.99970001\n",
      "Called solve_next_item: s: (0, 1), t: 3\n",
      "State: (0, 1), s_: (1, 1)\n",
      "Time_est: 3, Cum_discount: 2.99970001, Loss_rate: -1\n",
      "Just Loss Term: -2.99970001\n",
      "Adding reward: 93.00209965003499, Net: 90.002399640035\n",
      "Multiplying with prob_t: 1.0: Exp_task_reward: 90.002399640035\n",
      "Called solve_next_item: s: (1, 1), t: 6\n",
      "For s_: (1, 1), t_: 6, Qs: {None: 0}\n",
      "r: 90.002399640035 + r_: 0 * 0.9997000299990001 \n",
      "Total Reward: 90.002399640035\n",
      "Exp_total_reward: 90.002399640035\n",
      "For s_: (0, 1), t_: 3, Qs: {0: 90.002399640035}\n",
      "r: -2.99970001 + r_: 90.002399640035 * 0.9997000299990001 \n",
      "Total Reward: 86.97570161012499\n",
      "Exp_total_reward: 86.97570161012499\n",
      "Storing Q-value of SG A2: 86.97570161012499\n",
      "Policy:\n",
      "Action: 0\n",
      "s, t: ((0, 0), 0), a: 0, s_, t_: ((1, 0), 0)\n",
      "Action: 1\n",
      "s, t: ((1, 0), 0), a: 1, s_, t_: ((1, 1), 3)\n",
      "Slack Action Chosen. Action: None, q: 0 <= 10.000000000001101\n",
      "Q value\n",
      "SG A1, reward: -2.99970001 Q: 86.97570161012499\n",
      "[-2.99970001]\n",
      "SG A2, reward: -2.99970001 Q: 86.97570161012499\n",
      "[-2.99970001]\n",
      "Transferrred Q_s0 value down\n",
      "SG A1 value dict:86.97570161012499\n",
      "SG A2 value dict:86.97570161012499\n",
      "*********** MDP ***********\n",
      "Solving goal as: SG A1\n",
      "SG A1 Val: 86.97570161012499\n",
      "Solving for following items\n",
      "Task A11, Imp: 30, Int: 0, Ess: True\n",
      "Task A12, Imp: 30, Int: 0, Ess: True\n",
      "Task A13, Imp: 30, Int: 0, Ess: True\n",
      "Value: 86.97570161012499\n",
      "Called solve_next_item: s: (0, 0, 0), t: 0\n",
      "State: (0, 0, 0), s_: (1, 0, 0)\n",
      "Time_est: 1, Cum_discount: 1.0, Loss_rate: -1\n",
      "Just Loss Term: -1.0\n",
      "Adding reward: 0.0, Net: -1.0\n",
      "Multiplying with prob_t: 1.0: Exp_task_reward: -1.0\n",
      "Called solve_next_item: s: (1, 0, 0), t: 1\n",
      "State: (1, 0, 0), s_: (1, 1, 0)\n",
      "Time_est: 1, Cum_discount: 1.0, Loss_rate: -1\n",
      "Just Loss Term: -1.0\n",
      "Adding reward: 0.0, Net: -1.0\n",
      "Multiplying with prob_t: 1.0: Exp_task_reward: -1.0\n",
      "Called solve_next_item: s: (1, 1, 0), t: 2\n",
      "State: (1, 1, 0), s_: (1, 1, 1)\n",
      "Time_est: 1, Cum_discount: 1.0, Loss_rate: -1\n",
      "Just Loss Term: -1.0\n",
      "Adding reward: 86.97570161012499, Net: 85.97570161012499\n",
      "Multiplying with prob_t: 1.0: Exp_task_reward: 85.97570161012499\n",
      "Called solve_next_item: s: (1, 1, 1), t: 3\n",
      "For s_: (1, 1, 1), t_: 3, Qs: {None: 0}\n",
      "r: 85.97570161012499 + r_: 0 * 0.9999 \n",
      "Total Reward: 85.97570161012499\n",
      "Exp_total_reward: 85.97570161012499\n",
      "For s_: (1, 1, 0), t_: 2, Qs: {2: 85.97570161012499}\n",
      "r: -1.0 + r_: 85.97570161012499 * 0.9999 \n",
      "Total Reward: 84.96710403996397\n",
      "Exp_total_reward: 84.96710403996397\n",
      "State: (1, 0, 0), s_: (1, 0, 1)\n",
      "Time_est: 1, Cum_discount: 1.0, Loss_rate: -1\n",
      "Just Loss Term: -1.0\n",
      "Adding reward: 0.0, Net: -1.0\n",
      "Multiplying with prob_t: 1.0: Exp_task_reward: -1.0\n",
      "Called solve_next_item: s: (1, 0, 1), t: 2\n",
      "State: (1, 0, 1), s_: (1, 1, 1)\n",
      "Time_est: 1, Cum_discount: 1.0, Loss_rate: -1\n",
      "Just Loss Term: -1.0\n",
      "Adding reward: 86.97570161012499, Net: 85.97570161012499\n",
      "Multiplying with prob_t: 1.0: Exp_task_reward: 85.97570161012499\n",
      "Called solve_next_item: s: (1, 1, 1), t: 3\n",
      "For s_: (1, 1, 1), t_: 3, Qs: {None: 0}\n",
      "r: 85.97570161012499 + r_: 0 * 0.9999 \n",
      "Total Reward: 85.97570161012499\n",
      "Exp_total_reward: 85.97570161012499\n",
      "For s_: (1, 0, 1), t_: 2, Qs: {1: 85.97570161012499}\n",
      "r: -1.0 + r_: 85.97570161012499 * 0.9999 \n",
      "Total Reward: 84.96710403996397\n",
      "Exp_total_reward: 84.96710403996397\n",
      "For s_: (1, 0, 0), t_: 1, Qs: {1: 84.96710403996397, 2: 84.96710403996397}\n",
      "r: -1.0 + r_: 84.96710403996397 * 0.9999 \n",
      "Total Reward: 83.95860732955998\n",
      "Exp_total_reward: 83.95860732955998\n",
      "Storing Q-value of Task A11: 83.95860732955998\n",
      "State: (0, 0, 0), s_: (0, 1, 0)\n",
      "Time_est: 1, Cum_discount: 1.0, Loss_rate: -1\n",
      "Just Loss Term: -1.0\n",
      "Adding reward: 0.0, Net: -1.0\n",
      "Multiplying with prob_t: 1.0: Exp_task_reward: -1.0\n",
      "Called solve_next_item: s: (0, 1, 0), t: 1\n",
      "State: (0, 1, 0), s_: (1, 1, 0)\n",
      "Time_est: 1, Cum_discount: 1.0, Loss_rate: -1\n",
      "Just Loss Term: -1.0\n",
      "Adding reward: 0.0, Net: -1.0\n",
      "Multiplying with prob_t: 1.0: Exp_task_reward: -1.0\n",
      "Called solve_next_item: s: (1, 1, 0), t: 2\n",
      "For s_: (1, 1, 0), t_: 2, Qs: {2: 85.97570161012499}\n",
      "r: -1.0 + r_: 85.97570161012499 * 0.9999 \n",
      "Total Reward: 84.96710403996397\n",
      "Exp_total_reward: 84.96710403996397\n",
      "State: (0, 1, 0), s_: (0, 1, 1)\n",
      "Time_est: 1, Cum_discount: 1.0, Loss_rate: -1\n",
      "Just Loss Term: -1.0\n",
      "Adding reward: 0.0, Net: -1.0\n",
      "Multiplying with prob_t: 1.0: Exp_task_reward: -1.0\n",
      "Called solve_next_item: s: (0, 1, 1), t: 2\n",
      "State: (0, 1, 1), s_: (1, 1, 1)\n",
      "Time_est: 1, Cum_discount: 1.0, Loss_rate: -1\n",
      "Just Loss Term: -1.0\n",
      "Adding reward: 86.97570161012499, Net: 85.97570161012499\n",
      "Multiplying with prob_t: 1.0: Exp_task_reward: 85.97570161012499\n",
      "Called solve_next_item: s: (1, 1, 1), t: 3\n",
      "For s_: (1, 1, 1), t_: 3, Qs: {None: 0}\n",
      "r: 85.97570161012499 + r_: 0 * 0.9999 \n",
      "Total Reward: 85.97570161012499\n",
      "Exp_total_reward: 85.97570161012499\n",
      "For s_: (0, 1, 1), t_: 2, Qs: {0: 85.97570161012499}\n",
      "r: -1.0 + r_: 85.97570161012499 * 0.9999 \n",
      "Total Reward: 84.96710403996397\n",
      "Exp_total_reward: 84.96710403996397\n",
      "For s_: (0, 1, 0), t_: 1, Qs: {0: 84.96710403996397, 2: 84.96710403996397}\n",
      "r: -1.0 + r_: 84.96710403996397 * 0.9999 \n",
      "Total Reward: 83.95860732955998\n",
      "Exp_total_reward: 83.95860732955998\n",
      "Storing Q-value of Task A12: 83.95860732955998\n",
      "State: (0, 0, 0), s_: (0, 0, 1)\n",
      "Time_est: 1, Cum_discount: 1.0, Loss_rate: -1\n",
      "Just Loss Term: -1.0\n",
      "Adding reward: 0.0, Net: -1.0\n",
      "Multiplying with prob_t: 1.0: Exp_task_reward: -1.0\n",
      "Called solve_next_item: s: (0, 0, 1), t: 1\n",
      "State: (0, 0, 1), s_: (1, 0, 1)\n",
      "Time_est: 1, Cum_discount: 1.0, Loss_rate: -1\n",
      "Just Loss Term: -1.0\n",
      "Adding reward: 0.0, Net: -1.0\n",
      "Multiplying with prob_t: 1.0: Exp_task_reward: -1.0\n",
      "Called solve_next_item: s: (1, 0, 1), t: 2\n",
      "For s_: (1, 0, 1), t_: 2, Qs: {1: 85.97570161012499}\n",
      "r: -1.0 + r_: 85.97570161012499 * 0.9999 \n",
      "Total Reward: 84.96710403996397\n",
      "Exp_total_reward: 84.96710403996397\n",
      "State: (0, 0, 1), s_: (0, 1, 1)\n",
      "Time_est: 1, Cum_discount: 1.0, Loss_rate: -1\n",
      "Just Loss Term: -1.0\n",
      "Adding reward: 0.0, Net: -1.0\n",
      "Multiplying with prob_t: 1.0: Exp_task_reward: -1.0\n",
      "Called solve_next_item: s: (0, 1, 1), t: 2\n",
      "For s_: (0, 1, 1), t_: 2, Qs: {0: 85.97570161012499}\n",
      "r: -1.0 + r_: 85.97570161012499 * 0.9999 \n",
      "Total Reward: 84.96710403996397\n",
      "Exp_total_reward: 84.96710403996397\n",
      "For s_: (0, 0, 1), t_: 1, Qs: {0: 84.96710403996397, 1: 84.96710403996397}\n",
      "r: -1.0 + r_: 84.96710403996397 * 0.9999 \n",
      "Total Reward: 83.95860732955998\n",
      "Exp_total_reward: 83.95860732955998\n",
      "Storing Q-value of Task A13: 83.95860732955998\n",
      "Policy:\n",
      "Action: 0\n",
      "s, t: ((0, 0, 0), 0), a: 0, s_, t_: ((1, 0, 0), 0)\n",
      "Action: 1\n",
      "s, t: ((1, 0, 0), 0), a: 1, s_, t_: ((1, 1, 0), 1)\n",
      "Action: 2\n",
      "s, t: ((1, 1, 0), 1), a: 2, s_, t_: ((1, 1, 1), 2)\n",
      "Slack Action Chosen. Action: None, q: 0 <= 10.000000000001101\n",
      "Q value\n",
      "Task A11, reward: -1.0 Q: 83.95860732955998\n",
      "[-1.0]\n",
      "Task A12, reward: -1.0 Q: 83.95860732955998\n",
      "[-1.0]\n",
      "Task A13, reward: -1.0 Q: 83.95860732955998\n",
      "[-1.0]\n",
      "Transferrred Q_s0 value down\n",
      "Task A11 value dict:83.95860732955998\n",
      "Task A12 value dict:83.95860732955998\n",
      "Task A13 value dict:83.95860732955998\n",
      "Saving Q: SG A1\n",
      "*********** MDP ***********\n",
      "Solving goal as: Task A11\n",
      "*********** MDP ***********\n",
      "Solving goal as: Task A12\n",
      "*********** MDP ***********\n",
      "Solving goal as: Task A13\n",
      "*********** MDP ***********\n",
      "Solving goal as: SG A2\n",
      "SG A2 Val: 86.97570161012499\n",
      "Solving for following items\n",
      "Task A21, Imp: 3, Int: 0, Ess: True\n",
      "Task A22, Imp: 3, Int: 0, Ess: True\n",
      "Task A23, Imp: 4, Int: 0, Ess: True\n",
      "Value: 86.97570161012499\n",
      "Called solve_next_item: s: (0, 0, 0), t: 0\n",
      "State: (0, 0, 0), s_: (1, 0, 0)\n",
      "Time_est: 1, Cum_discount: 1.0, Loss_rate: -1\n",
      "Just Loss Term: -1.0\n",
      "Adding reward: 0.0, Net: -1.0\n",
      "Multiplying with prob_t: 1.0: Exp_task_reward: -1.0\n",
      "Called solve_next_item: s: (1, 0, 0), t: 1\n",
      "State: (1, 0, 0), s_: (1, 1, 0)\n",
      "Time_est: 1, Cum_discount: 1.0, Loss_rate: -1\n",
      "Just Loss Term: -1.0\n",
      "Adding reward: 0.0, Net: -1.0\n",
      "Multiplying with prob_t: 1.0: Exp_task_reward: -1.0\n",
      "Called solve_next_item: s: (1, 1, 0), t: 2\n",
      "State: (1, 1, 0), s_: (1, 1, 1)\n",
      "Time_est: 1, Cum_discount: 1.0, Loss_rate: -1\n",
      "Just Loss Term: -1.0\n",
      "Adding reward: 86.97570161012499, Net: 85.97570161012499\n",
      "Multiplying with prob_t: 1.0: Exp_task_reward: 85.97570161012499\n",
      "Called solve_next_item: s: (1, 1, 1), t: 3\n",
      "For s_: (1, 1, 1), t_: 3, Qs: {None: 0}\n",
      "r: 85.97570161012499 + r_: 0 * 0.9999 \n",
      "Total Reward: 85.97570161012499\n",
      "Exp_total_reward: 85.97570161012499\n",
      "For s_: (1, 1, 0), t_: 2, Qs: {2: 85.97570161012499}\n",
      "r: -1.0 + r_: 85.97570161012499 * 0.9999 \n",
      "Total Reward: 84.96710403996397\n",
      "Exp_total_reward: 84.96710403996397\n",
      "State: (1, 0, 0), s_: (1, 0, 1)\n",
      "Time_est: 1, Cum_discount: 1.0, Loss_rate: -1\n",
      "Just Loss Term: -1.0\n",
      "Adding reward: 0.0, Net: -1.0\n",
      "Multiplying with prob_t: 1.0: Exp_task_reward: -1.0\n",
      "Called solve_next_item: s: (1, 0, 1), t: 2\n",
      "State: (1, 0, 1), s_: (1, 1, 1)\n",
      "Time_est: 1, Cum_discount: 1.0, Loss_rate: -1\n",
      "Just Loss Term: -1.0\n",
      "Adding reward: 86.97570161012499, Net: 85.97570161012499\n",
      "Multiplying with prob_t: 1.0: Exp_task_reward: 85.97570161012499\n",
      "Called solve_next_item: s: (1, 1, 1), t: 3\n",
      "For s_: (1, 1, 1), t_: 3, Qs: {None: 0}\n",
      "r: 85.97570161012499 + r_: 0 * 0.9999 \n",
      "Total Reward: 85.97570161012499\n",
      "Exp_total_reward: 85.97570161012499\n",
      "For s_: (1, 0, 1), t_: 2, Qs: {1: 85.97570161012499}\n",
      "r: -1.0 + r_: 85.97570161012499 * 0.9999 \n",
      "Total Reward: 84.96710403996397\n",
      "Exp_total_reward: 84.96710403996397\n",
      "For s_: (1, 0, 0), t_: 1, Qs: {1: 84.96710403996397, 2: 84.96710403996397}\n",
      "r: -1.0 + r_: 84.96710403996397 * 0.9999 \n",
      "Total Reward: 83.95860732955998\n",
      "Exp_total_reward: 83.95860732955998\n",
      "Storing Q-value of Task A21: 83.95860732955998\n",
      "State: (0, 0, 0), s_: (0, 1, 0)\n",
      "Time_est: 1, Cum_discount: 1.0, Loss_rate: -1\n",
      "Just Loss Term: -1.0\n",
      "Adding reward: 0.0, Net: -1.0\n",
      "Multiplying with prob_t: 1.0: Exp_task_reward: -1.0\n",
      "Called solve_next_item: s: (0, 1, 0), t: 1\n",
      "State: (0, 1, 0), s_: (1, 1, 0)\n",
      "Time_est: 1, Cum_discount: 1.0, Loss_rate: -1\n",
      "Just Loss Term: -1.0\n",
      "Adding reward: 0.0, Net: -1.0\n",
      "Multiplying with prob_t: 1.0: Exp_task_reward: -1.0\n",
      "Called solve_next_item: s: (1, 1, 0), t: 2\n",
      "For s_: (1, 1, 0), t_: 2, Qs: {2: 85.97570161012499}\n",
      "r: -1.0 + r_: 85.97570161012499 * 0.9999 \n",
      "Total Reward: 84.96710403996397\n",
      "Exp_total_reward: 84.96710403996397\n",
      "State: (0, 1, 0), s_: (0, 1, 1)\n",
      "Time_est: 1, Cum_discount: 1.0, Loss_rate: -1\n",
      "Just Loss Term: -1.0\n",
      "Adding reward: 0.0, Net: -1.0\n",
      "Multiplying with prob_t: 1.0: Exp_task_reward: -1.0\n",
      "Called solve_next_item: s: (0, 1, 1), t: 2\n",
      "State: (0, 1, 1), s_: (1, 1, 1)\n",
      "Time_est: 1, Cum_discount: 1.0, Loss_rate: -1\n",
      "Just Loss Term: -1.0\n",
      "Adding reward: 86.97570161012499, Net: 85.97570161012499\n",
      "Multiplying with prob_t: 1.0: Exp_task_reward: 85.97570161012499\n",
      "Called solve_next_item: s: (1, 1, 1), t: 3\n",
      "For s_: (1, 1, 1), t_: 3, Qs: {None: 0}\n",
      "r: 85.97570161012499 + r_: 0 * 0.9999 \n",
      "Total Reward: 85.97570161012499\n",
      "Exp_total_reward: 85.97570161012499\n",
      "For s_: (0, 1, 1), t_: 2, Qs: {0: 85.97570161012499}\n",
      "r: -1.0 + r_: 85.97570161012499 * 0.9999 \n",
      "Total Reward: 84.96710403996397\n",
      "Exp_total_reward: 84.96710403996397\n",
      "For s_: (0, 1, 0), t_: 1, Qs: {0: 84.96710403996397, 2: 84.96710403996397}\n",
      "r: -1.0 + r_: 84.96710403996397 * 0.9999 \n",
      "Total Reward: 83.95860732955998\n",
      "Exp_total_reward: 83.95860732955998\n",
      "Storing Q-value of Task A22: 83.95860732955998\n",
      "State: (0, 0, 0), s_: (0, 0, 1)\n",
      "Time_est: 1, Cum_discount: 1.0, Loss_rate: -1\n",
      "Just Loss Term: -1.0\n",
      "Adding reward: 0.0, Net: -1.0\n",
      "Multiplying with prob_t: 1.0: Exp_task_reward: -1.0\n",
      "Called solve_next_item: s: (0, 0, 1), t: 1\n",
      "State: (0, 0, 1), s_: (1, 0, 1)\n",
      "Time_est: 1, Cum_discount: 1.0, Loss_rate: -1\n",
      "Just Loss Term: -1.0\n",
      "Adding reward: 0.0, Net: -1.0\n",
      "Multiplying with prob_t: 1.0: Exp_task_reward: -1.0\n",
      "Called solve_next_item: s: (1, 0, 1), t: 2\n",
      "For s_: (1, 0, 1), t_: 2, Qs: {1: 85.97570161012499}\n",
      "r: -1.0 + r_: 85.97570161012499 * 0.9999 \n",
      "Total Reward: 84.96710403996397\n",
      "Exp_total_reward: 84.96710403996397\n",
      "State: (0, 0, 1), s_: (0, 1, 1)\n",
      "Time_est: 1, Cum_discount: 1.0, Loss_rate: -1\n",
      "Just Loss Term: -1.0\n",
      "Adding reward: 0.0, Net: -1.0\n",
      "Multiplying with prob_t: 1.0: Exp_task_reward: -1.0\n",
      "Called solve_next_item: s: (0, 1, 1), t: 2\n",
      "For s_: (0, 1, 1), t_: 2, Qs: {0: 85.97570161012499}\n",
      "r: -1.0 + r_: 85.97570161012499 * 0.9999 \n",
      "Total Reward: 84.96710403996397\n",
      "Exp_total_reward: 84.96710403996397\n",
      "For s_: (0, 0, 1), t_: 1, Qs: {0: 84.96710403996397, 1: 84.96710403996397}\n",
      "r: -1.0 + r_: 84.96710403996397 * 0.9999 \n",
      "Total Reward: 83.95860732955998\n",
      "Exp_total_reward: 83.95860732955998\n",
      "Storing Q-value of Task A23: 83.95860732955998\n",
      "Policy:\n",
      "Action: 0\n",
      "s, t: ((0, 0, 0), 0), a: 0, s_, t_: ((1, 0, 0), 0)\n",
      "Action: 1\n",
      "s, t: ((1, 0, 0), 0), a: 1, s_, t_: ((1, 1, 0), 1)\n",
      "Action: 2\n",
      "s, t: ((1, 1, 0), 1), a: 2, s_, t_: ((1, 1, 1), 2)\n",
      "Slack Action Chosen. Action: None, q: 0 <= 10.000000000001101\n",
      "Q value\n",
      "Task A21, reward: -1.0 Q: 83.95860732955998\n",
      "[-1.0]\n",
      "Task A22, reward: -1.0 Q: 83.95860732955998\n",
      "[-1.0]\n",
      "Task A23, reward: -1.0 Q: 83.95860732955998\n",
      "[-1.0]\n",
      "Transferrred Q_s0 value down\n",
      "Task A21 value dict:83.95860732955998\n",
      "Task A22 value dict:83.95860732955998\n",
      "Task A23 value dict:83.95860732955998\n",
      "Saving Q: SG A2\n",
      "*********** MDP ***********\n",
      "Solving goal as: Task A21\n",
      "*********** MDP ***********\n",
      "Solving goal as: Task A22\n",
      "*********** MDP ***********\n",
      "Solving goal as: Task A23\n",
      "Key: SG A1\n",
      "Key: SG A2\n",
      "SG A1\n",
      "Task A11 83.95860732955998\n",
      "Task A12 83.95860732955998\n",
      "Task A13 83.95860732955998\n",
      "SG A2\n",
      "Task A21 83.95860732955998\n",
      "Task A22 83.95860732955998\n",
      "Task A23 83.95860732955998\n",
      "best_q: 83.95860732955998\n",
      "173.95140322024997\n",
      "Bias: 28.882554155263943\n",
      "Task A11: r: -1.0, Next_Q: 84.96710403996397, f*: 1.008496710403989 , Final: 28.991900536708332\n",
      "Task A12: r: -1.0, Next_Q: 84.96710403996397, f*: 1.008496710403989 , Final: 28.991900536708332\n",
      "Task A13: r: -1.0, Next_Q: 84.96710403996397, f*: 1.008496710403989 , Final: 28.991900536708332\n",
      "Task A21: r: -1.0, Next_Q: 84.96710403996397, f*: 1.008496710403989 , Final: 28.991900536708332\n",
      "Task A22: r: -1.0, Next_Q: 84.96710403996397, f*: 1.008496710403989 , Final: 28.991900536708332\n",
      "Task A23: r: -1.0, Next_Q: 84.96710403996397, f*: 1.008496710403989 , Final: 28.991900536708332\n",
      "\n",
      "Total sum of pseudo-rewards: 173.95\n",
      "\n",
      "Optimal Rewards\n",
      "Task: Task A11, PRS: 28.992\n",
      "Task: Task A12, PRS: 28.992\n",
      "Task: Task A13, PRS: 28.992\n",
      "Task: Task A21, PRS: 28.992\n",
      "Task: Task A22, PRS: 28.992\n",
      "Task: Task A23, PRS: 28.992\n",
      "Net PR Sum: 173.95140322025\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'SG A1': <todolistMDP.to_do_list.MDP at 0x1129e5650>,\n",
       " 'SG A2': <todolistMDP.to_do_list.MDP at 0x112a70250>}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main.solve(flag=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-6c1d4800e2dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'expected'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'prs' is not defined"
     ]
    }
   ],
   "source": [
    "np.round(prs['expected'][task.description],3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "aa = {'Task A11':2443.2213859906774,\n",
    "'Task A12':2443.467432023965,\n",
    "'Task A13':2443.467432023965,\n",
    "'Task A21':2435.941701753954,\n",
    "'Task A22':2436.42236271223,\n",
    "'Task A23':2436.4229627122304,\n",
    "'Task B11':689.8025736403886,\n",
    "'Task B12':689.9137529316523,\n",
    "'Task B21':678.0327115063275,\n",
    "'Task B22':678.0277126061875,\n",
    "'Task B23':678.0327113063476,\n",
    "'Task B24':677.5248615899078,\n",
    "'Task B25':678.0327115063275,\n",
    "'Task C11':-385.7673298588262,\n",
    "'Task C12':-385.72855309584133,\n",
    "'Task C21':-400.7462975510561,\n",
    "'Task C22':-403.7079147471334,\n",
    "'Task C23':-400.9019004132446,\n",
    "'Task C24':-400.70641935528613}\n",
    "tasks = np.array(main.tasks)\n",
    "pr_val = np.array([-1 * aa[task.description] for task in tasks])\n",
    "pr_val = np.array(pr_val)\n",
    "inds = pr_val.argsort()\n",
    "optimal_tasks = tasks[inds]\n",
    "for task in optimal_tasks:\n",
    "#     rr = np.round(aa[task.description], 3)\n",
    "    pr = np.round(aa[task.description], 3)\n",
    "    print(f'Task: {task.description}, PRS: {pr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Goal A, - Value: 10, Deadline: 12, \n",
      "* SG A1 - Intrinsic Reward: 0, Essential: True,Importance: 90, Time: 3\n",
      "\t Task A11 - Intrinsic Reward: 0, Essential: True,Importance: 30, Time: 1\n",
      "\t Taskx A12 - Intrinsic Reward: 0, Essential: True,Importance: 30, Time: 1\n",
      "\t Task A13 - Intrinsic Reward: 0, Essential: True,Importance: 30, Time: 1\n"
     ]
    }
   ],
   "source": [
    "def print_case(main):\n",
    "    keys = main.tree.keys()\n",
    "#     print(keys)\n",
    "    key = next(iter(main.tree))\n",
    "    \n",
    "    def recurse_print(item):\n",
    "        for child in item.children:\n",
    "            if 'SG' in child.description:\n",
    "                print(\"* \", end=\"\")\n",
    "            else:\n",
    "                print(\"\\t \", end=\"\")\n",
    "            print(f'{child.description} - Intrinsic Reward: {child.intrinsic_reward}, Essential: {child.essential},Importance: {child.importance}, Time: {child.time_est}')\n",
    "            recurse_print(child)\n",
    "            \n",
    "    for goal in main.tree[key]:\n",
    "        print(f'** {goal.description}, - Value: {goal.value}, Deadline: {goal.deadline}, ')\n",
    "        recurse_print(goal)\n",
    "#         for subgoal in main.tree[goal]:\n",
    "#             print(subgoal)\n",
    "#         print(f'{goal.description}, - Value: {goal.value}, Deadline: {goal.deadline}, ')\n",
    "#         for subgoal in goal.children:\n",
    "#             print(f'{Subgoal: {subgoal.description}, }')\n",
    "print_case(main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-109-f724ac927d1f>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-109-f724ac927d1f>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    An impossible task will never see the negative goal value effect\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "An impossible task will never see the negative goal value effect\n",
    "Check exp_reward function\n",
    "check prs function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if mdp code is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mdptoolbox, mdptoolbox.example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 tasks. 1 Goal only.\n",
    "A1, A2, A3\n",
    "|A| = 3\n",
    "|S| = 2^3 = 8 \n",
    "S = [0,0,0], [0,0,1], [0,1,0], [1,0,0],\n",
    "                        [1,1,0], [1,0,1], [0,1,1],\n",
    "                        [1,1,1]]\n",
    "P[0,:,:] = []\n",
    "P[1,:,:]\n",
    "P[2,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0, 0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MDP.exec_action([0,0,0], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idx(s, S):\n",
    "    for i,_ in enumerate(S):\n",
    "        if S[i] == s:\n",
    "            return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s: [0, 0, 0], a: 0, s_:[1, 0, 0]\n",
      "s: [1, 0, 0], a: 0, s_:[1, 0, 0]\n",
      "s: [0, 1, 0], a: 0, s_:[1, 1, 0]\n",
      "s: [0, 0, 1], a: 0, s_:[1, 0, 1]\n",
      "s: [1, 1, 0], a: 0, s_:[1, 1, 0]\n",
      "s: [1, 0, 1], a: 0, s_:[1, 0, 1]\n",
      "s: [0, 1, 1], a: 0, s_:[1, 1, 1]\n",
      "s: [1, 1, 1], a: 0, s_:[1, 1, 1]\n",
      "s: [0, 0, 0], a: 1, s_:[0, 1, 0]\n",
      "s: [1, 0, 0], a: 1, s_:[1, 1, 0]\n",
      "s: [0, 1, 0], a: 1, s_:[0, 1, 0]\n",
      "s: [0, 0, 1], a: 1, s_:[0, 1, 1]\n",
      "s: [1, 1, 0], a: 1, s_:[1, 1, 0]\n",
      "s: [1, 0, 1], a: 1, s_:[1, 1, 1]\n",
      "s: [0, 1, 1], a: 1, s_:[0, 1, 1]\n",
      "s: [1, 1, 1], a: 1, s_:[1, 1, 1]\n",
      "s: [0, 0, 0], a: 2, s_:[0, 0, 1]\n",
      "s: [1, 0, 0], a: 2, s_:[1, 0, 1]\n",
      "s: [0, 1, 0], a: 2, s_:[0, 1, 1]\n",
      "s: [0, 0, 1], a: 2, s_:[0, 0, 1]\n",
      "s: [1, 1, 0], a: 2, s_:[1, 1, 1]\n",
      "s: [1, 0, 1], a: 2, s_:[1, 0, 1]\n",
      "s: [0, 1, 1], a: 2, s_:[0, 1, 1]\n",
      "s: [1, 1, 1], a: 2, s_:[1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "S = [[0,0,0], [1,0,0], [0,1,0], [0,0,1], [1,1,0], [1,0,1], [0,1,1], [1,1,1]]\n",
    "P = np.zeros([3, 8,8])\n",
    "for a in [0,1,2]:\n",
    "    for s in S:\n",
    "        s_ = MDP.exec_action(s, a)\n",
    "        print(f's: {S[get_idx(s,S)]}, a: {a}, s_:{S[get_idx(list(s_),S)]}')\n",
    "        P[a,get_idx(s,S), get_idx(list(s_),S)] = 1\n",
    "\n",
    "# P\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(sum(sum(P)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1] 0\n",
      "[1, 0, 1] 1\n",
      "[1, 1, 0] 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.  , -1.  , -1.  ],\n",
       "       [ 0.  , -1.  , -1.  ],\n",
       "       [-1.  ,  0.  , -1.  ],\n",
       "       [-1.  , -1.  ,  0.  ],\n",
       "       [ 0.  ,  0.  ,  3.58],\n",
       "       [ 0.  ,  3.58,  0.  ],\n",
       "       [ 3.58,  0.  ,  0.  ],\n",
       "       [ 0.  ,  0.  ,  0.  ]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R = np.zeros([8,3])\n",
    "for a in [0,1,2]:\n",
    "    for s in S:\n",
    "        s_ = MDP.exec_action(s, a)\n",
    "        if s != [1,1,1]:\n",
    "            if s_ == (1,1,1):\n",
    "                R[get_idx(list(s), S), a] = 4.58-1 #10-1\n",
    "                print(s, a)\n",
    "            elif s == list(s_):\n",
    "                R[get_idx(list(s), S), a] = 0\n",
    "            else:\n",
    "                R[get_idx(list(s), S), a] = -1\n",
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 2 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "# fh = mdptoolbox.mdp.QLearning(P, R, 0.99,n_iter=10000)\n",
    "N = 3\n",
    "fh = mdptoolbox.mdp.FiniteHorizon(P,R, 0.9, N)\n",
    "fh.run()\n",
    "# Q = fh.Q\n",
    "V = fh.V\n",
    "# print(V)\n",
    "# print(Q)\n",
    "# print(V[:,0])\n",
    "policy = fh.policy\n",
    "policy = policy[:,0]\n",
    "print(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for s in S:\n",
    "#     if s == [0, 0, 0]:\n",
    "#         print(Q[get_idx(s,S)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal policy: In state: [0, 0, 0], take action: 0, arrive to state(1, 0, 0), Reward: -1.0\n",
      "Optimal policy: In state: [1, 0, 0], take action: 1, arrive to state(1, 1, 0), Reward: -1.0\n",
      "Optimal policy: In state: [1, 1, 0], take action: 2, arrive to state(1, 1, 1), Reward: 9.0\n",
      "Net Reward: 7.0\n"
     ]
    }
   ],
   "source": [
    "s = [0,0,0]\n",
    "idx = 0\n",
    "cum_reward = 0\n",
    "while True:\n",
    "    a = policy[idx]\n",
    "    s_ = MDP.exec_action(s, a)\n",
    "    r = R[get_idx(s,S), a]\n",
    "    print(f'Optimal policy: In state: {s}, take action: {a}, arrive to state{s_}, Reward: {r}')\n",
    "    cum_reward += r\n",
    "    s = list(s_)\n",
    "    idx = get_idx(s,S)\n",
    "    if s_ == (1,1,1):\n",
    "        break\n",
    "print(f'Net Reward: {cum_reward}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item: Task A11 Time Estimate: 1\n",
      "Item: Taskx A12 Time Estimate: 1\n",
      "Item: Task A13 Time Estimate: 1\n",
      "Item: SG A1 Time Estimate: 3\n",
      "Item: Goal A Time Estimate: 3\n"
     ]
    }
   ],
   "source": [
    "d_bm_simple = [\n",
    "    Item(\n",
    "        description=\"Goal A\",\n",
    "        completed=False,\n",
    "        intrinsic_reward=0,\n",
    "        essential=True,\n",
    "        deadline=12,\n",
    "        time_est=TIME_SCALE * 3,\n",
    "        value=10,\n",
    "        today=True,\n",
    "        children=[\n",
    "            Item(\"SG A1\", time_est=TIME_SCALE * 3, essential=True, importance=100, value=10, intrinsic_reward=0, today=True,\n",
    "                 completed=False, deadline=12, children=[\n",
    "                Item(\"Task A11\", time_est=TIME_SCALE * 1, essential=True, importance=30, value=10, intrinsic_reward=0, today=True,\n",
    "                     completed=False, deadline=12),\n",
    "                Item(\"Taskx A12\", time_est=TIME_SCALE * 1, essential=True, importance=30, value=10, intrinsic_reward=0, today=True,\n",
    "                     completed=False, deadline=12),\n",
    "                Item(\"Task A13\", time_est=TIME_SCALE * 1, essential=True, importance=30, value=10, intrinsic_reward=0, today=True,\n",
    "                     completed=False, deadline=12)\n",
    "            ])\n",
    "        ])\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item: Root Time Estimate: 3\n"
     ]
    }
   ],
   "source": [
    "main = MainToDoList(d_bm_simple, gamma=0.9, loss_rate= LOSS_RATE, num_bins=N_BINS, penalty_rate=PLANNING_FALLACY_CONST,slack_reward_rate=SLACK_REWARD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.29"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10 - (1+ 0.9 + 0.9**2) #- (1+ 0.9 + 0.9**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<todolistMDP.to_do_list.Item at 0x112a11d90>,\n",
       " <todolistMDP.to_do_list.Item at 0x1129b8050>,\n",
       " <todolistMDP.to_do_list.Item at 0x1129b83d0>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main.tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********** In MainToDoList solve ***********\n",
      "*********** MDP ***********\n",
      "Solving goal as: Root\n",
      "Root Val: 10\n",
      "Solving for following items\n",
      "Goal A, Imp: 1.0, Int: 0, Ess: False\n",
      "Value: 10\n",
      "Called solve_next_item: s: (0,), t: 0\n",
      "State: (0,), s_: (1,)\n",
      "Time_est: 3, Cum_discount: 2.71, Loss_rate: -1\n",
      "Just Loss Term: -2.71\n",
      "Adding reward: 10.0, Net: 7.29\n",
      "Multiplying with prob_t: 1.0: Exp_task_reward: 7.29\n",
      "Called solve_next_item: s: (1,), t: 3\n",
      "For s_: (1,), t_: 3, Qs: {None: 0}\n",
      "r: 7.29 + r_: 0 * 0.7290000000000001 \n",
      "Total Reward: 7.29\n",
      "Exp_total_reward: 7.29\n",
      "Storing Q-value of Goal A: 7.29\n",
      "Policy:\n",
      "Action: 0\n",
      "s, t: ((0,), 0), a: 0, s_, t_: ((1,), 0)\n",
      "Slack Action Chosen. Action: None, q: 0 <= 0.010000000000000002\n",
      "Q value\n",
      "Goal A, reward: 7.29 Q: 7.29\n",
      "[7.29]\n",
      "Transferrred Q_s0 value down\n",
      "Goal A value dict:7.29\n",
      "*********** MDP ***********\n",
      "Solving goal as: Goal A\n",
      "Goal A Val: 7.29\n",
      "Solving for following items\n",
      "SG A1, Imp: 90, Int: 0, Ess: True\n",
      "Value: 7.29\n",
      "Called solve_next_item: s: (0,), t: 0\n",
      "State: (0,), s_: (1,)\n",
      "Time_est: 3, Cum_discount: 2.71, Loss_rate: -1\n",
      "Just Loss Term: -2.71\n",
      "Adding reward: 7.29, Net: 4.58\n",
      "Multiplying with prob_t: 1.0: Exp_task_reward: 4.58\n",
      "Called solve_next_item: s: (1,), t: 3\n",
      "For s_: (1,), t_: 3, Qs: {None: 0}\n",
      "r: 4.58 + r_: 0 * 0.7290000000000001 \n",
      "Total Reward: 4.58\n",
      "Exp_total_reward: 4.58\n",
      "Storing Q-value of SG A1: 4.58\n",
      "Policy:\n",
      "Action: 0\n",
      "s, t: ((0,), 0), a: 0, s_, t_: ((1,), 0)\n",
      "Slack Action Chosen. Action: None, q: 0 <= 0.010000000000000002\n",
      "Q value\n",
      "SG A1, reward: 4.58 Q: 4.58\n",
      "[4.58]\n",
      "Transferrred Q_s0 value down\n",
      "SG A1 value dict:4.58\n",
      "*********** MDP ***********\n",
      "Solving goal as: SG A1\n",
      "SG A1 Val: 4.58\n",
      "Solving for following items\n",
      "Task A11, Imp: 30, Int: 0, Ess: True\n",
      "Taskx A12, Imp: 30, Int: 0, Ess: True\n",
      "Task A13, Imp: 30, Int: 0, Ess: True\n",
      "Value: 4.58\n",
      "Called solve_next_item: s: (0, 0, 0), t: 0\n",
      "State: (0, 0, 0), s_: (1, 0, 0)\n",
      "Time_est: 1, Cum_discount: 1.0, Loss_rate: -1\n",
      "Just Loss Term: -1.0\n",
      "Adding reward: 0.0, Net: -1.0\n",
      "Multiplying with prob_t: 1.0: Exp_task_reward: -1.0\n",
      "Called solve_next_item: s: (1, 0, 0), t: 1\n",
      "State: (1, 0, 0), s_: (1, 1, 0)\n",
      "Time_est: 1, Cum_discount: 1.0, Loss_rate: -1\n",
      "Just Loss Term: -1.0\n",
      "Adding reward: 0.0, Net: -1.0\n",
      "Multiplying with prob_t: 1.0: Exp_task_reward: -1.0\n",
      "Called solve_next_item: s: (1, 1, 0), t: 2\n",
      "State: (1, 1, 0), s_: (1, 1, 1)\n",
      "Time_est: 1, Cum_discount: 1.0, Loss_rate: -1\n",
      "Just Loss Term: -1.0\n",
      "Adding reward: 4.58, Net: 3.58\n",
      "Multiplying with prob_t: 1.0: Exp_task_reward: 3.58\n",
      "Called solve_next_item: s: (1, 1, 1), t: 3\n",
      "For s_: (1, 1, 1), t_: 3, Qs: {None: 0}\n",
      "r: 3.58 + r_: 0 * 0.9 \n",
      "Total Reward: 3.58\n",
      "Exp_total_reward: 3.58\n",
      "For s_: (1, 1, 0), t_: 2, Qs: {2: 3.58}\n",
      "r: -1.0 + r_: 3.58 * 0.9 \n",
      "Total Reward: 2.222\n",
      "Exp_total_reward: 2.222\n",
      "State: (1, 0, 0), s_: (1, 0, 1)\n",
      "Time_est: 1, Cum_discount: 1.0, Loss_rate: -1\n",
      "Just Loss Term: -1.0\n",
      "Adding reward: 0.0, Net: -1.0\n",
      "Multiplying with prob_t: 1.0: Exp_task_reward: -1.0\n",
      "Called solve_next_item: s: (1, 0, 1), t: 2\n",
      "State: (1, 0, 1), s_: (1, 1, 1)\n",
      "Time_est: 1, Cum_discount: 1.0, Loss_rate: -1\n",
      "Just Loss Term: -1.0\n",
      "Adding reward: 4.58, Net: 3.58\n",
      "Multiplying with prob_t: 1.0: Exp_task_reward: 3.58\n",
      "Called solve_next_item: s: (1, 1, 1), t: 3\n",
      "For s_: (1, 1, 1), t_: 3, Qs: {None: 0}\n",
      "r: 3.58 + r_: 0 * 0.9 \n",
      "Total Reward: 3.58\n",
      "Exp_total_reward: 3.58\n",
      "For s_: (1, 0, 1), t_: 2, Qs: {1: 3.58}\n",
      "r: -1.0 + r_: 3.58 * 0.9 \n",
      "Total Reward: 2.222\n",
      "Exp_total_reward: 2.222\n",
      "For s_: (1, 0, 0), t_: 1, Qs: {1: 2.222, 2: 2.222}\n",
      "r: -1.0 + r_: 2.222 * 0.9 \n",
      "Total Reward: 0.9998\n",
      "Exp_total_reward: 0.9998\n",
      "Storing Q-value of Task A11: 0.9998\n",
      "State: (0, 0, 0), s_: (0, 1, 0)\n",
      "Time_est: 1, Cum_discount: 1.0, Loss_rate: -1\n",
      "Just Loss Term: -1.0\n",
      "Adding reward: 0.0, Net: -1.0\n",
      "Multiplying with prob_t: 1.0: Exp_task_reward: -1.0\n",
      "Called solve_next_item: s: (0, 1, 0), t: 1\n",
      "State: (0, 1, 0), s_: (1, 1, 0)\n",
      "Time_est: 1, Cum_discount: 1.0, Loss_rate: -1\n",
      "Just Loss Term: -1.0\n",
      "Adding reward: 0.0, Net: -1.0\n",
      "Multiplying with prob_t: 1.0: Exp_task_reward: -1.0\n",
      "Called solve_next_item: s: (1, 1, 0), t: 2\n",
      "For s_: (1, 1, 0), t_: 2, Qs: {2: 3.58}\n",
      "r: -1.0 + r_: 3.58 * 0.9 \n",
      "Total Reward: 2.222\n",
      "Exp_total_reward: 2.222\n",
      "State: (0, 1, 0), s_: (0, 1, 1)\n",
      "Time_est: 1, Cum_discount: 1.0, Loss_rate: -1\n",
      "Just Loss Term: -1.0\n",
      "Adding reward: 0.0, Net: -1.0\n",
      "Multiplying with prob_t: 1.0: Exp_task_reward: -1.0\n",
      "Called solve_next_item: s: (0, 1, 1), t: 2\n",
      "State: (0, 1, 1), s_: (1, 1, 1)\n",
      "Time_est: 1, Cum_discount: 1.0, Loss_rate: -1\n",
      "Just Loss Term: -1.0\n",
      "Adding reward: 4.58, Net: 3.58\n",
      "Multiplying with prob_t: 1.0: Exp_task_reward: 3.58\n",
      "Called solve_next_item: s: (1, 1, 1), t: 3\n",
      "For s_: (1, 1, 1), t_: 3, Qs: {None: 0}\n",
      "r: 3.58 + r_: 0 * 0.9 \n",
      "Total Reward: 3.58\n",
      "Exp_total_reward: 3.58\n",
      "For s_: (0, 1, 1), t_: 2, Qs: {0: 3.58}\n",
      "r: -1.0 + r_: 3.58 * 0.9 \n",
      "Total Reward: 2.222\n",
      "Exp_total_reward: 2.222\n",
      "For s_: (0, 1, 0), t_: 1, Qs: {0: 2.222, 2: 2.222}\n",
      "r: -1.0 + r_: 2.222 * 0.9 \n",
      "Total Reward: 0.9998\n",
      "Exp_total_reward: 0.9998\n",
      "Storing Q-value of Taskx A12: 0.9998\n",
      "State: (0, 0, 0), s_: (0, 0, 1)\n",
      "Time_est: 1, Cum_discount: 1.0, Loss_rate: -1\n",
      "Just Loss Term: -1.0\n",
      "Adding reward: 0.0, Net: -1.0\n",
      "Multiplying with prob_t: 1.0: Exp_task_reward: -1.0\n",
      "Called solve_next_item: s: (0, 0, 1), t: 1\n",
      "State: (0, 0, 1), s_: (1, 0, 1)\n",
      "Time_est: 1, Cum_discount: 1.0, Loss_rate: -1\n",
      "Just Loss Term: -1.0\n",
      "Adding reward: 0.0, Net: -1.0\n",
      "Multiplying with prob_t: 1.0: Exp_task_reward: -1.0\n",
      "Called solve_next_item: s: (1, 0, 1), t: 2\n",
      "For s_: (1, 0, 1), t_: 2, Qs: {1: 3.58}\n",
      "r: -1.0 + r_: 3.58 * 0.9 \n",
      "Total Reward: 2.222\n",
      "Exp_total_reward: 2.222\n",
      "State: (0, 0, 1), s_: (0, 1, 1)\n",
      "Time_est: 1, Cum_discount: 1.0, Loss_rate: -1\n",
      "Just Loss Term: -1.0\n",
      "Adding reward: 0.0, Net: -1.0\n",
      "Multiplying with prob_t: 1.0: Exp_task_reward: -1.0\n",
      "Called solve_next_item: s: (0, 1, 1), t: 2\n",
      "For s_: (0, 1, 1), t_: 2, Qs: {0: 3.58}\n",
      "r: -1.0 + r_: 3.58 * 0.9 \n",
      "Total Reward: 2.222\n",
      "Exp_total_reward: 2.222\n",
      "For s_: (0, 0, 1), t_: 1, Qs: {0: 2.222, 1: 2.222}\n",
      "r: -1.0 + r_: 2.222 * 0.9 \n",
      "Total Reward: 0.9998\n",
      "Exp_total_reward: 0.9998\n",
      "Storing Q-value of Task A13: 0.9998\n",
      "Policy:\n",
      "Action: 0\n",
      "s, t: ((0, 0, 0), 0), a: 0, s_, t_: ((1, 0, 0), 0)\n",
      "Action: 1\n",
      "s, t: ((1, 0, 0), 0), a: 1, s_, t_: ((1, 1, 0), 1)\n",
      "Action: 2\n",
      "s, t: ((1, 1, 0), 1), a: 2, s_, t_: ((1, 1, 1), 2)\n",
      "Slack Action Chosen. Action: None, q: 0 <= 0.010000000000000002\n",
      "Q value\n",
      "Task A11, reward: -1.0 Q: 0.9998\n",
      "[-1.0]\n",
      "Taskx A12, reward: -1.0 Q: 0.9998\n",
      "[-1.0]\n",
      "Task A13, reward: -1.0 Q: 0.9998\n",
      "[-1.0]\n",
      "Transferrred Q_s0 value down\n",
      "Task A11 value dict:0.9998\n",
      "Taskx A12 value dict:0.9998\n",
      "Task A13 value dict:0.9998\n",
      "Saving Q: SG A1\n",
      "*********** MDP ***********\n",
      "Solving goal as: Task A11\n",
      "*********** MDP ***********\n",
      "Solving goal as: Taskx A12\n",
      "*********** MDP ***********\n",
      "Solving goal as: Task A13\n",
      "Key: SG A1\n",
      "SG A1\n",
      "Task A11 0.9998\n",
      "Taskx A12 0.9998\n",
      "Task A13 0.9998\n",
      "best_q: 0.9998\n",
      "4.58\n",
      "Bias: 1.1822466666666667\n",
      "Task A11: r: -1.0, Next_Q: 2.222, f*: 1.2222 , Final: 1.5266666666666664\n",
      "Taskx A12: r: -1.0, Next_Q: 2.222, f*: 1.2222 , Final: 1.5266666666666664\n",
      "Task A13: r: -1.0, Next_Q: 2.222, f*: 1.2222 , Final: 1.5266666666666664\n",
      "\n",
      "Total sum of pseudo-rewards: 4.58\n",
      "\n",
      "Optimal Rewards\n",
      "Task: Task A11, PRS: 1.527\n",
      "Task: Taskx A12, PRS: 1.527\n",
      "Task: Task A13, PRS: 1.527\n",
      "Net PR Sum: 4.579999999999999\n"
     ]
    }
   ],
   "source": [
    "mdps = main.solve(flag=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.39"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7.1*0.9 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdps['SG A1'].items[0].get_time_est()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 0, 0): {0: {0: 0.9998, 1: 0.9998, 2: 0.9998}},\n",
       " (1, 0, 0): {1: {1: 2.222, 2: 2.222}},\n",
       " (1, 1, 0): {2: {2: 3.58}},\n",
       " (1, 1, 1): {3: {None: 0}},\n",
       " (1, 0, 1): {2: {1: 3.58}},\n",
       " (0, 1, 0): {1: {0: 2.222, 2: 2.222}},\n",
       " (0, 1, 1): {2: {0: 3.58}},\n",
       " (0, 0, 1): {1: {0: 2.222, 1: 2.222}}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdps['SG A1'].Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.58\n",
      "Optimal policy: In state: (0, 0, 0), take action: 0, arrive to state(1, 0, 0), Reward: -1.0\n",
      "Optimal policy: In state: (1, 0, 0), take action: 1, arrive to state(1, 1, 0), Reward: -1.0\n",
      "Optimal policy: In state: (1, 1, 0), take action: 2, arrive to state(1, 1, 1), Reward: 3.58\n",
      "Net Reward: 1.58\n"
     ]
    }
   ],
   "source": [
    "s = (0,0,0)\n",
    "t = 0\n",
    "mdp = mdps['SG A1']\n",
    "print(mdp.value)\n",
    "cum_reward = 0\n",
    "while True:\n",
    "    a = mdp.P[s][t]\n",
    "    s_ = MDP.exec_action(s, a)\n",
    "    item = mdps['SG A1'].items[a]\n",
    "    time_est = item.get_time_est()\n",
    "    cum_discount = mdp.get_cum_discount(time_est)\n",
    "    r = MDP.compute_total_loss(cum_discount=cum_discount, loss_rate=mdp.loss_rate)\n",
    "    r += mdp.get_reward(a,s_)\n",
    "    print(f'Optimal policy: In state: {s}, take action: {a}, arrive to state{s_}, Reward: {r}')\n",
    "    cum_reward += r\n",
    "    s = s_\n",
    "    t+= time_est\n",
    "    if s_ == (1,1,1):\n",
    "        break\n",
    "print(f'Net Reward: {cum_reward}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{<todolistMDP.to_do_list.Item at 0x113509c90>: 0.9998,\n",
       " <todolistMDP.to_do_list.Item at 0x135b57950>: 0.9998,\n",
       " <todolistMDP.to_do_list.Item at 0x135b57b50>: 0.9998}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdp.Q_s0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
